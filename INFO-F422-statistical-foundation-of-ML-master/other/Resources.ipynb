{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCXw9vS30g_X"
   },
   "source": [
    "Cette section reprend tout les aspects théoriques, ce document sera utilisé en guise de référence. Et plus encore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUxsPFZNO26P"
   },
   "source": [
    "# Assignement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znJrYFTppVG_"
   },
   "source": [
    "# Termes\n",
    "\n",
    "## Input\n",
    "\n",
    "**shape**: The number of elements in each dimension of a tensor. The shape is represented as a list of integers. For example, the following two-dimensional tensor has a shape of [3,4]:\n",
    "```\n",
    "[[5, 7, 6, 4],\n",
    " [2, 9, 4, 8],\n",
    " [3, 6, 5, 1]]\n",
    "``` \n",
    "\n",
    "fit (function):\n",
    "\n",
    "**label**: In supervised learning, the \"answer\" or \"result\" portion of an example. Each example in a labeled dataset consists of one or more features and a label. For instance, in a housing dataset, the features might include the number of bedrooms, the number of bathrooms, and the age of the house, while the label might be the house's price. In a spam detection dataset, the features might include the subject line, the sender, and the email message itself, while the label would probably be either \"spam\" or \"not spam.\"\n",
    "\n",
    "## Modèle\n",
    "\n",
    "**classifier**: A type of machine learning model for distinguishing among two or more discrete classes. For example, a natural language processing classification model could determine whether an input sentence was in French, Spanish, or Italian. Compare with regression model.\n",
    " \n",
    "**loss**: A measure of how far a model's predictions are from its label. Or, to phrase it more pessimistically, a measure of how bad the model is. To determine this value, a model must define a loss function. For example, linear regression models typically use mean squared error for a loss function, while logistic regression models use Log Loss.\n",
    " \n",
    "**gradient descent**: A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\n",
    "\n",
    "**optimizer**: A specific implementation of the gradient descent algorithm. TensorFlow's base class for optimizers is tf.train.Optimizer. Popular optimizers include:\n",
    "\n",
    "AdaGrad, which stands for ADAptive GRADient descent.\n",
    "Adam, which stands for ADAptive with Momentum.\n",
    "Different optimizers may leverage one or more of the following concepts to enhance the effectiveness of gradient descent on a given training set:\n",
    "\n",
    "momentum (Momentum)\n",
    "update frequency\n",
    "sparsity/regularization (Ftrl)\n",
    "\n",
    "## Prédiction\n",
    "\n",
    "**prediction**: A model's output when provided with an input example.\n",
    "\n",
    "source: https://developers.google.com/machine-learning/glossary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-TJELvwpY9K"
   },
   "source": [
    "# Concepts\n",
    "\n",
    "**Classification**: Sous-catégorie de l'apprentissage supervisé, la classification est le processus consistant à prendre une sorte d'entrée et à lui attribuer une étiquette. Les systèmes de classification sont généralement utilisés lorsque les prévisions sont de nature discrète ou «oui ou non». Exemple: mappage d'une image d'une personne à une classification masculine ou féminine. \n",
    "\n",
    "**Regression**: Une autre sous-catégorie d'apprentissage supervisé est utilisée lorsque la valeur prédite diffère d'une étiquette «oui ou non» car elle se situe quelque part sur un spectre continu. Des systèmes de régression pourraient être utilisés, par exemple, pour répondre aux questions «Combien?» ou \"Combien?\".\n",
    "\n",
    "**underfitting**: Producing a model with poor predictive ability because the model hasn't captured the complexity of the training data. Many problems can cause underfitting, including:\n",
    "\n",
    "- Training on the wrong set of features.\n",
    "- Training for too few epochs or at too low a learning rate.\n",
    "- Training with too high a regularization rate. \n",
    "\n",
    "**preprocessing**: fairnessProcessing data before it's used to train a model. Preprocessing could be as simple as removing words from an English text corpus that don't occur in the English dictionary, or could be as complex as re-expressing data points in a way that eliminates as many attributes that are correlated with sensitive attributes as possible. Preprocessing can help satisfy fairness constraints.\n",
    "\n",
    "source : https://blog.aylien.com/10-machine-learning-terms-explained-in-simple-english/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ozwYq-MpbuC"
   },
   "source": [
    "# Mail\n",
    "```\n",
    "Dear students,\n",
    "\n",
    "Below you will information about \n",
    "\n",
    "0) Next week class\n",
    "1) Email communication during the course\n",
    "2) ML projects\n",
    "3) Course content\n",
    "\n",
    "0) The class on 25 February will be completely devoted to Python. We will give a brief overview of Python itself, look at the Python Ecosystem for Machine Learning (numpy, scipy, matplotlib/seaborn).\n",
    "If you are familiar with these topics you can skip this class. \n",
    "\n",
    "1) When you send me mail related to the course the Subject should with ‘SFML:' for VUB students and 'INFO-F422:' for ULB students, e.g. 'INFO-F422: Project submission’.\n",
    "\n",
    "2) ML projects\n",
    "\n",
    "2a) You will be marked on ML projects. The default option for one person is described below. You can work together with one or more people but then the work presented should\n",
    "be twice that for a single person of you are working in a group of two, etc.\n",
    "\n",
    "2b) If you are working on a master or PhD thesis then you can submit a ML project related to your thesis instead of the default option. However, you have to discuss this with me beforehand\n",
    "and as soon as possible.\n",
    "\n",
    "2c) All ML projects are inn the form of self-contained Jupyter notebooks.  To see what I mean by self-contained see https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n",
    "as an example.\n",
    "\n",
    "2d) Default option\n",
    "\n",
    "You do two projects, one about classification and one about regression and you will submit one Jupyter notebook per project. Don’t forget to start the notebook with the title of the project, your name(s) and study program(s).\n",
    "For each project you use two datasets that you will use for training, validation and testing purposes.\n",
    "\n",
    "1) a synthetic dataset that you generate yourself. You can use the python module scipy.stats for that purpose.\n",
    "2) a real-world dataset, you can find them at https://www.kaggle.com/datasets, the UCI ML repository at https://archive.ics.uci.edu/ml/datasets.php, etc.\n",
    "           See the link  https://towardsdatascience.com/top-sources-for-machine-learning-datasets-bb6d0dc3378b for more information.\n",
    "\n",
    "And for both classification and regression you use at least 3 different ML-algorithms.\n",
    "\n",
    "3) Course contents. The course is based on two books.\n",
    "3a) Learning from Data by Learning by Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin. \n",
    "              Video lectures can be found at the YouTube Channel https://www.youtube.com/playlist?list=PLD63A284B7615313A. \n",
    "              The supplementary material and the slides will be soon available at the website of the AI Lab: https://ai.vub.ac.be/course/statistical-machine-learning/\n",
    "\n",
    "3b) A First Course in Machine Learning, 2nd edition, by Simon Rogers, Mark Girolami\n",
    "              We will cover during the classes\n",
    "The Bayesian Approach to Machine Learning\n",
    "Gaussian Processes, and \n",
    "Markov Chain Monte Carlo Sampling\n",
    "     \n",
    "     The rest of book is complementary to the first book.\n",
    "\n",
    "Kind regards,\n",
    "\n",
    "Prof. dr. Bernard Manderick\n",
    "Artificial Intelligence Lab\n",
    "Vrije Universiteit Brussel\n",
    "Pleinlaan 9, 3rd floor\n",
    "B-1050 Brussels, Belgium\n",
    "Email: Bernard.Manderick@vub.be\n",
    "Web Address: http://ai.vub.ac.be\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_glvHPShHaG"
   },
   "source": [
    "![](PLA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![no image](PLA2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhgs8XgYXkK4imBt/FMYrT",
   "collapsed_sections": [],
   "mount_file_id": "19KC8R-sJW6_4mptgnq8ammv9KRmHIHef",
   "name": "Resources.ipynb",
   "provenance": [
    {
     "file_id": "1tdCiPKWO_cDnjKYckP81CCDoHYarK-35",
     "timestamp": 1587306345531
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
